{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49af05a7",
   "metadata": {},
   "source": [
    "### Extract\n",
    "\n",
    "Goals:\n",
    "- Connect to chinook Database\n",
    "- Get data of customers table\n",
    "\n",
    "#### Connection to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30660219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Connect to the database\n",
    "db_connection_string = 'sqlite:///chinook.db'\n",
    "engine = create_engine(url=db_connection_string)\n",
    "# engine = create_engine(url=db_connection_string, connect_args={'username': 'cmadmin', 'password': 'adpassword'})\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb9a83",
   "metadata": {},
   "source": [
    "#### Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b999f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from a table into a DataFrame\n",
    "customers_df = pd.read_sql_table(table_name='customers', con=conn)\n",
    "customers_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6dcfb3",
   "metadata": {},
   "source": [
    "### Transformation (Optional)\n",
    "\n",
    "In reality, this is usually a very later step.\n",
    "\n",
    "Goals:\n",
    "- Filter for only USA customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675233a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_customers_df = customers_df[customers_df['Country']=='USA']\n",
    "usa_customers_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38be5e97",
   "metadata": {},
   "source": [
    "### Load\n",
    "\n",
    "Upload USA customer data into AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23069967",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY = '<ENTER ACCESS KEY>'\n",
    "SECRET_ACCESS_KEY = '<ENTER ACCESS SECRET>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d3a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 location\n",
    "bucket_name = 'cm-aws-s3-dev'\n",
    "folder = \"chinook\"\n",
    "subfolder = 'khanh98'\n",
    "s3_path = f\"s3://{bucket_name}/{folder}/{subfolder}\"\n",
    "filename = 'usa_customers'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6375d97c",
   "metadata": {},
   "source": [
    "#### Option 1: Pandas + s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838abffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "# Create an s3fs file system object with credentials\n",
    "s3 = s3fs.S3FileSystem(\n",
    "    key=ACCESS_KEY, \n",
    "    secret=SECRET_ACCESS_KEY, \n",
    "    client_kwargs={'region_name': 'ap-southeast-2'}\n",
    ")\n",
    "\n",
    "# Write the DataFrame to S3\n",
    "# csv format\n",
    "with s3.open(f'{s3_path}/{filename}.csv', 'w') as csv_f:\n",
    "    usa_customers_df.to_csv(csv_f, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0683351f",
   "metadata": {},
   "source": [
    "#### Option 2: boto3 + awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import awswrangler as wr\n",
    "\n",
    "# create s3 client using boto3 + credentials\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=ACCESS_KEY,\n",
    "    aws_secret_access_key=SECRET_ACCESS_KEY,\n",
    ")\n",
    "\n",
    "# upload result to s3 as parquet file \n",
    "wr.s3.to_parquet(\n",
    "    df=usa_customers_df,\n",
    "    path=f'{s3_path}/{filename}.parquet',\n",
    "    boto3_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e21dfd9",
   "metadata": {},
   "source": [
    "## ==================================================\n",
    "### Best Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30464089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine.base import Engine\n",
    "from pandas.core.frame import DataFrame\n",
    "import boto3\n",
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "def extract(\n",
    "    db_engine: Engine, \n",
    "    table_name: str\n",
    ") -> DataFrame:\n",
    "    # Connect to the database\n",
    "    conn = db_engine.connect()\n",
    "\n",
    "    # Read data from a table into a DataFrame\n",
    "    df = pd.read_sql_table(table_name=table_name, con=conn)\n",
    "\n",
    "    # close connection\n",
    "    conn.close()\n",
    "\n",
    "    # return data as DataFrame\n",
    "    return df\n",
    "\n",
    "def load(\n",
    "    df: DataFrame,\n",
    "    table_name: str,\n",
    "    aws_access_key_id: str,\n",
    "    aws_secret_access_key: str,\n",
    "    s3_path: dict\n",
    ") -> bool:\n",
    "    \n",
    "    # create s3 client using boto3 + credentials\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "    )\n",
    "\n",
    "    # upload result to s3 as parquet file\n",
    "    today = datetime.now(tz=pytz.timezone('Australia/Adelaide'))\n",
    "    year, month, day = today.strftime('%Y'), today.strftime('%m'), today.strftime('%d')\n",
    "\n",
    "    # Upload file to folder\n",
    "    file_path = f\"{s3_path}/year={year}/month={month}/day={day}/{table_name}.parquet\"\n",
    "\n",
    "    wr.s3.to_parquet(\n",
    "        df=df,\n",
    "        path=file_path,\n",
    "        boto3_session=session\n",
    "    )\n",
    "    print(f'Data successfully loaded into: {file_path}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b251f91f",
   "metadata": {},
   "source": [
    "#### Modular & Resuable Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875460b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Engine connection to the database\n",
    "db_connection_string = 'sqlite:///chinook.db'\n",
    "chinook_engine = create_engine(url=db_connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = extract(db_engine=chinook_engine, table_name='customers')\n",
    "customer_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6f0e0",
   "metadata": {},
   "source": [
    "#### Config-Driven Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f917567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pprint\n",
    "\n",
    "config_file = 'config.yml'\n",
    "\n",
    "with open(config_file) as f:\n",
    "    conf = yaml.safe_load(f)\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_conf = conf.get('source')\n",
    "target_conf = conf.get('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deecfcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name in source_conf.get('table'):\n",
    "    print(f\"{'='*20}  {table_name}  {'='*20}\")\n",
    "\n",
    "    # extract data\n",
    "    df = extract(\n",
    "            db_engine=chinook_engine, \n",
    "            table_name=table_name\n",
    "        )\n",
    "\n",
    "    # target authentication & location\n",
    "    s3_credentials = target_conf.get('credentials')\n",
    "    s3_location = target_conf.get('location')\n",
    "\n",
    "    # load to AWS S3\n",
    "    load(\n",
    "            df=df,\n",
    "            table_name=table_name,\n",
    "            aws_access_key_id=s3_credentials.get('aws_access_key_id'),\n",
    "            aws_secret_access_key=s3_credentials.get('aws_secret_access_key'),\n",
    "            s3_path=s3_location.get('path')\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
